{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0YSCOS5fO/3rzBZ9nGTWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelinetipa/MyDataCampJourney/blob/master/Joining_Data_with_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA MERGING BASICS**"
      ],
      "metadata": {
        "id": "rwM96mYmeML0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INNER JOIN**"
      ],
      "metadata": {
        "id": "oa4k4LlMvHEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ztwWVY4FdaVD"
      },
      "outputs": [],
      "source": [
        "# FIRST INNER JOIN\n",
        "\n",
        "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
        "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
        "\n",
        "# Print the value_counts to find the most popular fuel_type\n",
        "print(taxi_own_veh['fuel_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONE TO MANY MERGE\n",
        "\n",
        "# Merge the licenses and biz_owners table on account\n",
        "licenses_owners = licenses.merge(biz_owners, on='account')\n",
        "\n",
        "# Group the results by title then count the number of accounts\n",
        "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
        "\n",
        "# Sort the counted_df in descending order\n",
        "sorted_df = counted_df.sort_values(by='account', ascending = False)\n",
        "\n",
        "# Use .head() method to print the first few rows of sorted_df\n",
        "print(sorted_df.head())"
      ],
      "metadata": {
        "id": "hR0eZCYRhzsG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THREE TABLE MERGE\n",
        "\n",
        "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
        "licenses_zip_ward = licenses.merge(zip_demo, on='zip')\\\n",
        "            \t\t\t.merge(wards, on='ward')\n",
        "\n",
        "# Print the results by alderman and show median income\n",
        "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
      ],
      "metadata": {
        "id": "i11BKol9oolk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ONE TO MANY MERGE WITH MULTIPLE TABLES\n",
        "\n",
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on='ward') \\\n",
        "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
        "\n",
        "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
        "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'],\n",
        "                                   as_index=False).agg({'account':'count'})\n",
        "\n",
        "# Sort pop_vac_lic and print the results\n",
        "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'],\n",
        "                                             ascending=[False, True, True])\n",
        "\n",
        "# Print the top few rows of sorted_pop_vac_lic\n",
        "print(sorted_pop_vac_lic.head())"
      ],
      "metadata": {
        "id": "Trtz-yxnu4WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEFT JOIN**"
      ],
      "metadata": {
        "id": "jDR6_uQGxQPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COUNTING MISSING ROWS WITH LEFT JOIN\n",
        "\n",
        "# Merge the movies table with the financials table with a left join\n",
        "movies_financials = movies.merge(financials, on='id', how='left')\n",
        "\n",
        "# Count the number of rows in the budget column that are missing\n",
        "number_of_missing_fin = movies_financials['budget'].isna().sum()\n",
        "\n",
        "# Print the number of movies missing financials\n",
        "print(number_of_missing_fin)"
      ],
      "metadata": {
        "id": "--EFYFu4yvmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **OTHER JOIN**"
      ],
      "metadata": {
        "id": "u_1Ju-STzcmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RIGHT JOIN TO FIND UNIQUE MOVIES\n",
        "\n",
        "# Merge action_movies to the scifi_movies with right join\n",
        "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
        "                                   suffixes=('_act','_sci'))\n",
        "\n",
        "# From action_scifi, select only the rows where the genre_act column is null\n",
        "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]\n",
        "\n",
        "# Merge the movies and scifi_only tables with an inner join\n",
        "movies_and_scifi_only = movies.merge(scifi_only, how='inner', left_on='id', right_on='movie_id')\n",
        "\n",
        "# Print the first few rows and shape of movies_and_scifi_only\n",
        "print(movies_and_scifi_only.head())\n",
        "print(movies_and_scifi_only.shape)"
      ],
      "metadata": {
        "id": "mmp2roIJ1ijj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING OUTER JOIN TO SELECT ACTORS\n",
        "\n",
        "# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
        "iron_1_and_2 = iron_1_actors.merge(iron_2_actors,\n",
        "                                     on='id',\n",
        "                                     how='outer',\n",
        "                                     suffixes=('_1', '_2'))\n",
        "\n",
        "# Create an index that returns true if name_1 or name_2 are null\n",
        "m = ((iron_1_and_2['name_1'].isnull()) |\n",
        "     (iron_1_and_2['name_2'].isnull()))\n",
        "\n",
        "# Print the first few rows of iron_1_and_2\n",
        "print(iron_1_and_2[m].head())"
      ],
      "metadata": {
        "id": "dQwafWpR20Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MERGING A TABLE TO ITSELF**"
      ],
      "metadata": {
        "id": "3xFnyYM83mNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SELF JOIN\n",
        "\n",
        "# Merge the crews table to itself\n",
        "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
        "                                suffixes=('_dir','_crew'))\n",
        "\n",
        "# Create a boolean index to select the appropriate rows\n",
        "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') &\n",
        "                  (crews_self_merged['job_crew'] != 'Director'))\n",
        "direct_crews = crews_self_merged[boolean_filter]\n",
        "\n",
        "# Print the first few rows of direct_crews\n",
        "print(direct_crews.head())"
      ],
      "metadata": {
        "id": "ENY6XCqF6Ldz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MERGING ON INDEXES**"
      ],
      "metadata": {
        "id": "KNXUXXGC7ft7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge sequels and financials on index id\n",
        "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
        "\n",
        "# Self merge with suffixes as inner join with left on sequel and right on id\n",
        "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel',\n",
        "                             right_on='id', right_index=True,\n",
        "                             suffixes=('_org','_seq'))\n",
        "\n",
        "# Add calculation to subtract revenue_org from revenue_seq\n",
        "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
        "\n",
        "# Select the title_org, title_seq, and diff\n",
        "titles_diff = orig_seq[['title_org','title_seq','diff']]\n",
        "\n",
        "# Print the first rows of the sorted titles_diff\n",
        "print(titles_diff.sort_values('diff', ascending=False).head())"
      ],
      "metadata": {
        "id": "4xn3bk7j6NDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ADVANCED MERGING AND CONCATENATING**"
      ],
      "metadata": {
        "id": "xmWtN030JUR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PERFORMING A SEMI JOIN\n",
        "\n",
        "# Merge the non_mus_tcks and top_invoices tables on tid\n",
        "tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid')\n",
        "\n",
        "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
        "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
        "\n",
        "# Group the top_tracks by gid and count the tid rows\n",
        "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n",
        "\n",
        "# Merge the genres table to cnt_by_gid on gid and print\n",
        "print(cnt_by_gid.merge(genres, on='gid'))"
      ],
      "metadata": {
        "id": "7AjZPFSaJcjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCATENATING WITH KEYS\n",
        "\n",
        "# Concatenate the tables and add keys\n",
        "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep],\n",
        "                            keys=('7Jul', '8Aug', '9Sep'))\n",
        "\n",
        "# Group the invoices by the index keys and find avg of the total column\n",
        "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
        "\n",
        "# Bar plot of avg_inv_by_month\n",
        "avg_inv_by_month.plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nhf1UsWKYAQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCATENATE AND MERGE TO FIND COMMON SONGS\n",
        "\n",
        "# Concatenate the classic tables vertically\n",
        "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
        "\n",
        "# Concatenate the pop tables vertically\n",
        "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
        "\n",
        "# Merge classic_18_19 with pop_18_19\n",
        "classic_pop = classic_18_19.merge(pop_18_19, on='tid', how='inner')\n",
        "\n",
        "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
        "popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n",
        "\n",
        "# Print popular chart\n",
        "print(popular_classic)"
      ],
      "metadata": {
        "id": "VADXScVuaGHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING .merge_ordered\n",
        "\n",
        "# Use merge_ordered() to merge gdp and sp500, and forward fill missing values\n",
        "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date',\n",
        "                             how='left',  fill_method='ffill')\n",
        "\n",
        "# Subset the merged DataFrame to include only GDP and S&P 500 returns\n",
        "gdp_returns = gdp_sp500[['gdp', 'returns']]\n",
        "\n",
        "# Compute and print the correlation matrix\n",
        "print(gdp_returns.corr())\n"
      ],
      "metadata": {
        "id": "BsXNbs4rcsxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING .merge_asof()\n",
        "\n",
        "jpm_wells = pd.merge_asof(jpm, wells, on='date_time', suffixes=('', '_wells'), direction='nearest')\n",
        "\n",
        "jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on='date_time', suffixes=('_jpm', '_bac'),direction='nearest')\n",
        "\n",
        "\n",
        "# Compute price diff\n",
        "price_diffs = jpm_wells_bac.diff()\n",
        "\n",
        "# Plot the price diff of the close of jpm, wells and bac only\n",
        "price_diffs.plot(y=['close_jpm', 'close_wells', 'close_bac'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZha60PddStW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING .merge_asof() to create dataset\n",
        "\n",
        "# Merge gdp and recession on date using merge_asof()\n",
        "gdp_recession = pd.merge_asof(gdp, recession, on='date')\n",
        "\n",
        "# Create a list based on the row value of gdp_recession['econ_status']\n",
        "is_recession = ['r' if s == 'recession' else 'g' for s in gdp_recession['econ_status']]\n",
        "\n",
        "# Plot a bar chart of gdp_recession\n",
        "gdp_recession.plot(kind='bar', y='gdp', x='date', color=is_recession, rot=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_B_eZrOlegzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SUBSETTING ROWS WITH .QUERY()\n",
        "\n",
        "# Merge gdp and pop on date and country with fill\n",
        "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
        "\n",
        "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
        "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']\n",
        "\n",
        "# Pivot data so gdp_per_capita, where index is date and columns is country\n",
        "gdp_pivot = gdp_pop.pivot_table('gdp_per_capita', 'date', 'country')\n",
        "\n",
        "# Select dates equal to or greater than 1991-01-01\n",
        "recent_gdp_pop = gdp_pivot.query('date >= \"1991-01-01\"')\n",
        "\n",
        "# Plot recent_gdp_pop\n",
        "recent_gdp_pop.plot(rot=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7ctJ9W4f570"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING .melt()\n",
        "\n",
        "# Use melt on ten_yr, unpivot everything besides the metric column\n",
        "bond_perc = ten_yr.melt(id_vars=['metric'], var_name='date', value_name='close')\n",
        "\n",
        "# Use query on bond_perc to select only the rows where metric=close\n",
        "bond_perc_close = bond_perc.query(\"metric == 'close'\")\n",
        "\n",
        "# Merge (ordered) dji and bond_perc_close on date with an inner join\n",
        "dow_bond = pd.merge_ordered(dji, bond_perc_close, on='date', how='inner', suffixes=('_dow', '_bond'))\n",
        "\n",
        "# Plot only the close_dow and close_bond columns\n",
        "dow_bond.plot(kind='line', y=['close_dow', 'close_bond'], x='date', rot=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gPbBG4sqgq3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COURSE WRAP UP**\n",
        "\n",
        "Data merging basics\n",
        "- Inner join using `.merge()`\n",
        "- one to one and one to many relationships\n",
        "- merging multiple tables\n",
        "\n",
        "Merging tables with different join types\n",
        "- left, right and outer joins\n",
        "- merging a table to itslef and merging on indexes\n",
        "\n",
        "Advanced merging and concatenating\n",
        "- filtering joins\n",
        "  - semi and anti joins\n",
        "- combining data vertically with `.concat()`\n",
        "- verify data intergrity\n",
        "\n",
        "Merging ordered and time-series data\n",
        "- ordered data\n",
        "  - `merge_ordered()` and `merge_asof()`\n",
        "- manipulating data with `.melt()`"
      ],
      "metadata": {
        "id": "lHaeFk6Ng0NK"
      }
    }
  ]
}